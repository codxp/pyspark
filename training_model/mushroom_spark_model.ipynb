{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Information: (classes: edible=e, poisonous=p)\n",
    "\n",
    "cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "\n",
    "cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "\n",
    "cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "\n",
    "bruises: bruises=t,no=f\n",
    "\n",
    "odor: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n",
    "\n",
    "gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "\n",
    "gill-spacing: close=c,crowded=w,distant=d\n",
    "\n",
    "gill-size: broad=b,narrow=n\n",
    "\n",
    "gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "\n",
    "stalk-shape: enlarging=e,tapering=t\n",
    "\n",
    "stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?\n",
    "\n",
    "stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "\n",
    "stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "\n",
    "stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "\n",
    "stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "\n",
    "veil-type: partial=p,universal=u\n",
    "\n",
    "veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "\n",
    "ring-number: none=n,one=o,two=t\n",
    "\n",
    "ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
    "\n",
    "spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
    "\n",
    "population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
    "\n",
    "habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, LinearSVC, LinearSVCModel, GBTClassificationModel, RandomForestClassificationModel, DecisionTreeClassificationModel, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"Mushrooms_Classification\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.20.13:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Mushrooms_Classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11686f190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
       "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
       "       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
       "       'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
       "       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
       "       'ring-type', 'spore-print-color', 'population', 'habitat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas = pd.read_csv(\"mushrooms.csv\")\n",
    "col = df_pandas.columns\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv(\"mushrooms.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "|class|cap-shape|cap-surface|cap-color|bruises|odor|gill-attachment|gill-spacing|gill-size|gill-color|stalk-shape|stalk-root|stalk-surface-above-ring|stalk-surface-below-ring|stalk-color-above-ring|stalk-color-below-ring|veil-type|veil-color|ring-number|ring-type|spore-print-color|population|habitat|\n",
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "|    p|        x|          s|        n|      t|   p|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
      "|    e|        x|          s|        y|      t|   a|              f|           c|        b|         k|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      g|\n",
      "|    e|        b|          s|        w|      t|   l|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      m|\n",
      "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         n|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
      "|    e|        x|          s|        g|      f|   n|              f|           w|        b|         k|          t|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        e|                n|         a|      g|\n",
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- cap-shape: string (nullable = true)\n",
      " |-- cap-surface: string (nullable = true)\n",
      " |-- cap-color: string (nullable = true)\n",
      " |-- bruises: string (nullable = true)\n",
      " |-- odor: string (nullable = true)\n",
      " |-- gill-attachment: string (nullable = true)\n",
      " |-- gill-spacing: string (nullable = true)\n",
      " |-- gill-size: string (nullable = true)\n",
      " |-- gill-color: string (nullable = true)\n",
      " |-- stalk-shape: string (nullable = true)\n",
      " |-- stalk-root: string (nullable = true)\n",
      " |-- stalk-surface-above-ring: string (nullable = true)\n",
      " |-- stalk-surface-below-ring: string (nullable = true)\n",
      " |-- stalk-color-above-ring: string (nullable = true)\n",
      " |-- stalk-color-below-ring: string (nullable = true)\n",
      " |-- veil-type: string (nullable = true)\n",
      " |-- veil-color: string (nullable = true)\n",
      " |-- ring-number: string (nullable = true)\n",
      " |-- ring-type: string (nullable = true)\n",
      " |-- spore-print-color: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- habitat: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/30 11:43:18 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    df_pyspark.withColumnRenamed(\"class\", \"classe\")\n",
    "      .withColumnRenamed(\"cap-shape\", \"forme_du_chapeau\")\n",
    "      .withColumnRenamed(\"cap-surface\", \"surface_du_chapeau\")\n",
    "      .withColumnRenamed(\"cap-color\", \"couleur_du_chapeau\")\n",
    "      .withColumnRenamed(\"bruises\", \"meurtrissures\")\n",
    "      .withColumnRenamed(\"odor\", \"odeur\")\n",
    "      .withColumnRenamed(\"gill-attachment\", \"attache_des_lamelles\")\n",
    "      .withColumnRenamed(\"gill-spacing\", \"espacement_des_lamelles\")\n",
    "      .withColumnRenamed(\"gill-size\", \"taille_des_lamelles\")\n",
    "      .withColumnRenamed(\"gill-color\", \"couleur_des_lamelles\")\n",
    "      .withColumnRenamed(\"stalk-shape\", \"forme_du_pied\")\n",
    "      .withColumnRenamed(\"stalk-root\", \"racine_du_pied\")\n",
    "      .withColumnRenamed(\"stalk-surface-above-ring\", \"surface_du_pied_au_dessus_de_lanneau\")\n",
    "      .withColumnRenamed(\"stalk-surface-below-ring\", \"surface_du_pied_en_dessous_de_lanneau\")\n",
    "      .withColumnRenamed(\"stalk-color-above-ring\", \"couleur_du_pied_au_dessus_de_lanneau\")\n",
    "      .withColumnRenamed(\"stalk-color-below-ring\", \"couleur_du_pied_en_dessous_de_lanneau\")\n",
    "      .withColumnRenamed(\"veil-type\", \"type_de_voile\")\n",
    "      .withColumnRenamed(\"veil-color\", \"couleur_du_voile\")\n",
    "      .withColumnRenamed(\"ring-number\", \"nombre_danneaux\")\n",
    "      .withColumnRenamed(\"ring-type\", \"type_danneau\")\n",
    "      .withColumnRenamed(\"spore-print-color\", \"couleur_de_lempreinte_des_spores\")\n",
    "      .withColumnRenamed(\"population\", \"population\")\n",
    "      .withColumnRenamed(\"habitat\", \"habitat\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/30 11:43:24 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/10/30 11:43:24 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "# Liste des colonnes à indexer (toutes les colonnes du DataFrame)\n",
    "columns = df.columns\n",
    "\n",
    "# Indexer la colonne \"classe\" pour la transformer en étiquette numérique\n",
    "label_indexer = StringIndexer(inputCol=\"classe\", outputCol=\"classe_indexed\")\n",
    "\n",
    "# Créer les indexeurs pour chaque colonne sauf la colonne \"classe\" qui est la colonne de label\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_indexed\", handleInvalid=\"keep\") for col in columns[1:]]\n",
    "\n",
    "# Assembler toutes les colonnes indexées en une seule colonne de caractéristiques\n",
    "assembler = VectorAssembler(inputCols=[col + \"_indexed\" for col in columns[1:]], outputCol=\"features\")\n",
    "\n",
    "# Définir le modèle de régression logistique\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"classe_indexed\", maxIter=10)\n",
    "\n",
    "# Créer le pipeline avec les étapes de transformation et le modèle\n",
    "pipeline = Pipeline(stages=[label_indexer] + indexers + [assembler, lr])\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=17)\n",
    "\n",
    "# Entraîner le pipeline\n",
    "pipeline_model = pipeline.fit(train)\n",
    "\n",
    "# Sauvegarder le pipeline complet\n",
    "pipeline_model.save(\"models/logisticRegressionPipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|classe_indexed|prediction|\n",
      "+--------------+----------+\n",
      "|           0.0|       0.0|\n",
      "|           0.0|       0.0|\n",
      "|           0.0|       0.0|\n",
      "|           0.0|       0.0|\n",
      "|           0.0|       0.0|\n",
      "+--------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/30 11:43:32 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = pipeline_model.transform(test)\n",
    "\n",
    "# Afficher les prédictions\n",
    "predictions.select(\"classe_indexed\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_LG = BinaryClassificationEvaluator(labelCol=\"classe_indexed\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_LG = roc_LG.evaluate(predictions)\n",
    "accuracy_LG = BinaryClassificationEvaluator(labelCol=\"classe_indexed\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "accuracy_LG = accuracy_LG.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC : 0.9938532755185764\n",
      "Accuracy : 0.9880963818824631\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC : {roc_LG}\")\n",
    "print(f\"Accuracy : {accuracy_LG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluate DecisionTree Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'classe')\n",
    "decisiontree_train = dt.fit(train)\n",
    "decisiontree_train.save(\"decisiontree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_decisiontree = DecisionTreeClassificationModel.load(\"decisiontree\")\n",
    "predictions = load_decisiontree.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_DT = BinaryClassificationEvaluator(labelCol=\"classe\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_DT = roc_DT.evaluate(predictions)\n",
    "accuracy_DT = BinaryClassificationEvaluator(labelCol=\"classe\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "accuracy_DT = accuracy_DT.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluate RandomForest Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'classe')\n",
    "randomForest_train = rf.fit(train)\n",
    "randomForest_train.save(\"randomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_randomForest = RandomForestClassificationModel.load(\"randomForest\")\n",
    "predictions = load_randomForest.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_RF = BinaryClassificationEvaluator(labelCol=\"classe\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_RF = roc_RF.evaluate(predictions)\n",
    "accuracy_RF = BinaryClassificationEvaluator(labelCol=\"classe\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "accuracy_RF = accuracy_RF.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluate Gradient-BoostTree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GBTClassifier(featuresCol = 'features', labelCol = 'classe')\n",
    "gbtModel_train = gb.fit(train)\n",
    "gbtModel_train.save(\"gbtModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_gbtModel = GBTClassificationModel.load(\"gbtModel\")\n",
    "predictions = load_gbtModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_GB = BinaryClassificationEvaluator(labelCol=\"classe\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_GB = roc_GB.evaluate(predictions)\n",
    "accuracy_GB = BinaryClassificationEvaluator(labelCol=\"classe\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "accuracy_GB = accuracy_GB.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluate SVM Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = LinearSVC(featuresCol = 'features', labelCol = 'classe')\n",
    "sv_train = sv.fit(train)\n",
    "# sv_train.save(\"linearSVCModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadmodel = LinearSVCModel.load(\"linearSVCModel\")\n",
    "predictions = loadmodel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_SV = BinaryClassificationEvaluator(labelCol=\"classe\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_SV = roc_SV.evaluate(predictions)\n",
    "accuracy_SV = BinaryClassificationEvaluator(labelCol=\"classe\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "accuracy_SV = accuracy_SV.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame with the model names and their scores\n",
    "model_scores = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient-Boosted Tree', 'Linear SVC'],\n",
    "    'ROC Score': [roc_LG, roc_DT, roc_RF, roc_GB, roc_SV],\n",
    "    'PR Score': [accuracy_LG, accuracy_DT, accuracy_GB, accuracy_RF, accuracy_SV]  # Add other PR scores if available\n",
    "})\n",
    "print(model_scores)\n",
    "# Plot the scores using seaborn\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot ROC Scores\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Model', y='ROC Score', data=model_scores)\n",
    "plt.title('ROC Scores')\n",
    "plt.ylabel('ROC Score')\n",
    "plt.xlabel('Model')\n",
    "plt.ylim(0.97, 1.0)  # Adjust the y-axis to better visualize the differences\n",
    "\n",
    "# Plot PR Scores\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Model', y='PR Score', data=model_scores)\n",
    "plt.title('PR Scores')\n",
    "plt.ylabel('PR Score')\n",
    "plt.xlabel('Model')\n",
    "plt.ylim(0.97, 1.0)  # Adjust the y-axis to better visualize the differences\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Score (Receiver Operating Characteristic) :\n",
    "\n",
    "Le score ROC, ou AUC (Area Under the Curve), mesure la capacité d'un modèle à distinguer entre les classes positives et négatives.\n",
    "\n",
    "Un score de 1.0 signifie une séparation parfaite des classes (aucune erreur de classification), tandis qu'un score de 0.5 signifie que le modèle ne fait pas mieux qu'un tirage aléatoire.\n",
    "\n",
    "Ici, tous les modèles ont un ROC élevé (proches de 1.0), indiquant qu’ils séparent très bien les classes.\n",
    "\n",
    "### PR Score (Precision-Recall) :\n",
    "\n",
    "Le score PR, ou courbe de précision-rappel, est souvent plus informatif que le ROC dans les cas de déséquilibre de classes, car il se concentre sur la précision (taux de vrais positifs sur les positifs prédits) et le rappel (capacité de capturer les vrais positifs).\n",
    "\n",
    "Un PR de 1.0 indique également une précision et un rappel parfaits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "Random Forest et Gradient-Boosted Tree offrent les meilleures performances en termes de ROC et PR scores.\n",
    "\n",
    "Si la simplicité et la rapidité sont des priorités, Logistic Regression ou Linear SVC peuvent être préférables malgré des scores légèrement inférieurs.\n",
    "\n",
    "Random Forest et Gradient-Boosted Tree sont les modèles de choix si les performances maximales sont l'objectif, bien que Gradient-Boosted Tree puisse offrir une meilleure généralisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
